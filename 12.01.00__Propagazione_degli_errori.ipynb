{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propagazione degli errori\n",
    "\n",
    "Se abbiamo stimato un parametro come \n",
    "\n",
    "$\\theta = \\hat{\\theta}\\pm \\sigma_\\hat{\\theta}$\n",
    "\n",
    "può succedere di aver bisogno di un altro parametro $\\eta$ che si ottine tramite una trasformazione a partire da $\\theta$:\n",
    "\n",
    "$\\eta = \\varphi\\,(\\theta\\,)$\n",
    "\n",
    "La stima di $\\eta$:\n",
    "\n",
    "$\\eta = \\hat{\\eta}\\pm \\sigma_\\hat{\\eta}$\n",
    "\n",
    "La determinazione di $\\hat{\\eta}$ e in particolare del suo errore $\\sigma_\\hat{\\eta}$ a partire da $\\hat{\\theta}\\pm \\sigma_\\hat{\\theta}$ è noto come *propagazione degli errori*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evitare la propagazione degli errori\n",
    "\n",
    "La scelta migliore, quando possibile, è sempre *evitare la propagazione degli errori*.\n",
    "\n",
    "Si può, infatti, riparametrizzare la funzione di verosimiglianza in termini di $\\eta$ anziché di $\\theta$ e procedere con l'inferenza direttamente sulla variabile di interesse. La stima e la sua incertezza saranno fatte direttamente sul parametro di interesse.\n",
    "\n",
    "In formule, andrà riscritta la funzione di verosimiglianza partendo da:\n",
    "\n",
    "$p_\\theta(x_1,\\cdots,x_n;\\theta)$\n",
    "\n",
    "come:\n",
    "\n",
    "$p_\\eta(x_1,\\cdots,x_n;\\eta) = p_\\theta(x_1,\\cdots,x_n;\\varphi^{-1}(\\eta))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propagazione degli errori con inferenza bayesiana\n",
    "\n",
    "La distribuzione a posteriori per il parametro $\\theta$ si scrive come:\n",
    "\n",
    "$\\displaystyle p(\\theta;x_1,\\cdots,x_n) = \\frac{p(x_1, \\cdots, x_n;\\theta)\\,\\pi(\\theta)}{\\int p(x_1, \\cdots, x_n;\\theta^\\prime)\\,\\pi(\\theta^\\prime)\\,\\mathrm{d}\\theta^\\prime}$\n",
    "\n",
    "A questo punto, la distribuzione di $\\eta=\\varphi(\\theta)$ si ottine con le usuali regole di trasformazione di variabile che abbiamo già visto. Ossia:\n",
    "\n",
    "$\\displaystyle p(\\eta;x_1,\\cdots,x_n) = \\int_{-\\infty}^{+\\infty}\\!\\!\\! \\delta(\\eta - \\varphi(\\theta))\\,p(\\theta;x_1,\\cdots,x_n)\\,\\mathrm{d}\\theta$\n",
    "\n",
    "Nella pratica, non è necessario calcolare la funzione trasformata quanndo la stima di $\\displaystyle p(\\theta;x_1,\\cdots,x_n)$ è fatta attraverso un metodo Monte Carlo. Il risultato del Monte Carlo, infatti, sarà una sequenza di valori $\\theta^{(1)},\\cdots,\\theta^{(N)}$ distribuiti secondo la $\\displaystyle p(\\theta;x_1,\\cdots,x_n)$. Basterà quindi trasformare tutti i valori della sequenza ed ottenere:  \n",
    "\n",
    "$\\eta^{(1)},\\cdots,\\eta^{(N)} = \\varphi(\\theta^{(1)}),\\cdots,\\varphi(\\theta^{(N)})$\n",
    "\n",
    "La sequenza sarà naturalmente distribuita secondo $\\displaystyle p(\\eta;x_1,\\cdots,x_n)$, che potrà essere determinata interpolando l'istogramma dei valori, oppure con il metodo della *kernel density estimation*.\n",
    "\n",
    "Da notare che **non è detto** che il valore più probabile di $\\theta=\\hat{\\theta}$ corrisponda al valore più probabile di $\\eta=\\hat{\\eta}$ attraverso la trasformazione $\\hat{\\eta}=\\varphi(\\hat{\\theta})$.\n",
    "\n",
    "Comunque, gli intervalli di credibilità si potranno calcolare sulla distribuzione a posteriori trasformata. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propagazione degli errori con inferenza frequentista\n",
    "\n",
    "Il metodo della massima verosimiglianza è invariante per riparametrizzazione. Il valore stimato $\\theta=\\hat{\\theta}$ corrisponderà quindi alla stima $\\eta=\\hat{\\eta}$ attraverso la trasformazione $\\hat{\\eta}=\\varphi(\\hat{\\theta})$.\n",
    "\n",
    "Se non c'è modo di calcolare la stima di massima verosimiglianza usando la funzione di verosimiglianza trasformata, bisognerà ricorrere a metodi approssimativi, in particolare sviluppando $\\varphi(\\theta)$ intorno al valore stimato $\\hat{\\theta}$:\n",
    "\n",
    "$\\displaystyle\\eta = \\varphi(\\theta) \\simeq \\varphi(\\hat{\\theta}) + \\frac{\\partial \\varphi}{\\partial\\theta}(\\hat{\\theta}) (\\theta-\\hat{\\theta})+\\cdots$\n",
    "\n",
    "Da questa trasformazione lineare possiamo dedurre che l'intervallo $[\\hat{\\theta}-\\sigma_\\hat{\\theta},\\hat{\\theta}+\\sigma_\\hat{\\theta}]$ si trasformerà in $[\\hat{\\eta}-\\sigma_\\hat{\\eta},\\hat{\\eta}+\\sigma_\\hat{\\eta}]$\n",
    "\n",
    "dove:\n",
    "\n",
    "$\\hat{\\eta}=\\varphi(\\hat{\\theta})$\n",
    "\n",
    "e:\n",
    "\n",
    "$\\displaystyle\\sigma_\\hat{\\eta} = \\left|\\frac{\\partial \\varphi}{\\partial\\theta}(\\hat{\\theta})\\right|\\sigma_\\hat{\\theta}$\n",
    "\n",
    "Più in generale, in presenza di $k$ variabili $\\theta_1,\\cdots,\\theta_k$ trasformate in $h$ variabili $\\eta_1,\\cdots,\\eta_h$, abbiamo una regola di trasformazione della *matrice di covarianza* delle incertezze data da:\n",
    "\n",
    "\n",
    "$\\displaystyle H_{ij} = \\sum_{l,m}\\frac{\\partial \\varphi_i}{\\partial\\theta_l}\\frac{\\partial \\varphi_j}{\\partial\\theta_m} \\Theta_{lm} $\n",
    "\n",
    "Dove $\\Theta_{lm}$ e $H_{ij}$ sono le matrici di covarianza dei parametri $\\theta_1,\\cdots,\\theta_k$ e $\\eta_1,\\cdots,\\eta_h$.\n",
    "\n",
    "Nel caso della trasformazione di due variabili $x, y$ in una variabile $z$ abbiamo:\n",
    "\n",
    "$\\displaystyle\\sigma_z^2 = \n",
    "\\left(\\frac{\\partial z}{\\partial x}\\right)^2\\sigma_x^2+\n",
    "\\left(\\frac{\\partial z}{\\partial y}\\right)^2\\sigma_y^2+\n",
    "\\left(\\frac{\\partial z}{\\partial x}\\right)\\left(\\frac{\\partial z}{\\partial y}\\right)\\mathbb{C}\\mathrm{ov}(x,y)+\n",
    "\\left(\\frac{\\partial z}{\\partial y}\\right)\\left(\\frac{\\partial x}{\\partial y}\\right)\\mathbb{C}\\mathrm{ov}(y,x)=\\\\\n",
    "\\displaystyle=\\left(\\frac{\\partial z}{\\partial x}\\right)^2\\sigma_x^2+\n",
    "\\left(\\frac{\\partial z}{\\partial y}\\right)^2\\sigma_y^2+\n",
    "2\\left(\\frac{\\partial z}{\\partial x}\\right)\\left(\\frac{\\partial z}{\\partial y}\\right)\\mathbb{C}\\mathrm{ov}(x,y)\n",
    "$\n",
    "\n",
    "In particolare, abbiamo:\n",
    "\n",
    "$\\displaystyle\\sigma_{x\\pm y}^2 = \n",
    "\\sigma_x^2+\n",
    "\\sigma_y^2\\pm\n",
    "2\\,\\rho\\,\\sigma_x\\sigma_y\n",
    "$\n",
    "\n",
    "$\\displaystyle\\left(\\frac{\\sigma_{xy}}{xy}\\right)^2 = \n",
    "\\left(\\frac{\\sigma_x}{x}\\right)^2+\n",
    "\\left(\\frac{\\sigma_y}{y}\\right)^2+\n",
    "\\frac{2\\,\\rho\\,\\sigma_x\\sigma_y}{xy}\n",
    "$\n",
    "\n",
    "$\\displaystyle\\left(\\frac{\\sigma_{x/y}}{x/y}\\right)^2 = \n",
    "\\left(\\frac{\\sigma_x}{x}\\right)^2+\n",
    "\\left(\\frac{\\sigma_y}{y}\\right)^2-\n",
    "\\frac{2\\,\\rho\\,\\sigma_x\\sigma_y}{x/y}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errori asimmetrici\n",
    "\n",
    "Nel caso di inferenza bayesiana, la propagazione di una distribuzione a posteriori asimmetrica procede naturalmente come detto sopra.\n",
    "\n",
    "Per il metodo di massima verosimiglianza, invece, non esiste una procedura consolidata per propagare incertezze asimmetriche. La questione è stata dibattuta a lungo. \n",
    "\n",
    "<span style=\"color: red\">In particolare, per la propagazione di errori asimmetrici alla somma di due variabili:\n",
    "</span>\n",
    "$x = \\hat{x}^{+\\sigma_x^+}_{-\\sigma_x^-}$, \n",
    "$y = \\hat{y}^{+\\sigma_y^+}_{-\\sigma_y^-}$\n",
    "\n",
    "<span style=\"color: red\">In alcuni casi è stata suggerita la seguente prescrizione **errata** \n",
    "</span>\n",
    "\n",
    "$\\displaystyle x+y = \\hat{x}+\\hat{y}^{+\\sqrt{\\sigma_x^{+2}+\\sigma_y^{+2}}}_{-\\sqrt{\\sigma_x^{-2}+\\sigma_y^{-2}}}$, \n",
    "\n",
    "<span style=\"color: red\">**Questa prescrizione non ha alcuna base statistica.**\n",
    "</span>\n",
    "\n",
    "Per approfondimenti (che esulano dallo scopo di questo corso):\n",
    "\n",
    "* [Asymmetric Errors](https://www.slac.stanford.edu/econf/C030908/papers/WEMT002.pdf), R. Barlow, PHYSTAT2003,  SLAC, Stanford, California, September 8-11, 2003\n",
    "* [Asymmetric Statistical Errors](https://arxiv.org/abs/physics/0406120), R. Barlow, MAN/HEP/04/02, arXiv:physics/0406120, 24/6/2004\n",
    "* [Asymmetric Systematic Errors](https://arxiv.org/abs/physics/0306138), R. Barlow, MAN/HEP/03/02, 3/6/2003, arXiv:physics/0306138"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errori massimi\n",
    "\n",
    "Esistono in letterature regole per la propagazione degli errori massimi. Sono utili per trovare i massimi intervalli di escursione a seguito della trasformazione di variabili. Gli errori massimi non hanno però alcuna proprietà statistica rilevante, per cui non ne parleremo in queste lezioni."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python\n",
    "\n",
    "Esiste un pacchetto python, [```uncertainties```](https://pythonhosted.org/uncertainties/), che tratta la propagazione delle incertezze. Tuttavia, non è particolarmente usato tra i fisici.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spunti per esercizi\n",
    "\n",
    "* Scrivere la formula di propagazione degli errori per $x^\\alpha$\n",
    "\n",
    "$x=\\hat{x}\\pm\\sigma_{\\hat{x}} \\implies x^\\alpha =\\hat{x}^\\alpha\\pm |\\alpha x^{\\alpha -1}| \\sigma_{\\hat{x}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Scrivere la formula di propagazione degli errori per $\\log{x}$\n",
    "\n",
    "$\\displaystyle x=\\hat{x}\\pm\\sigma_{\\hat{x}} \\implies \\log x =\\log\\hat{x}\\pm \\frac{1}{\\hat{x}}\\sigma_{\\hat{x}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Scrivere la formula di propagazione della matrice di covarianza per $x/y$\n",
    "\n",
    "$\\displaystyle \\hat{x}, \\hat{y}; C_{xy} \\implies \\widehat{x/y} = \\frac{\\hat{x}}{\\hat{y}}$\n",
    "\n",
    "$\\displaystyle \\frac{\\partial x/y}{x} = \\frac{1}{y}$\n",
    "\n",
    "$\\displaystyle \\frac{\\partial x/y}{y} = -\\frac{x}{y^2}$\n",
    "\n",
    "$\\displaystyle \\sigma_{\\widehat{x/y}}^2 = \\left(\\frac{1}{\\hat{y}}\\right)^2\\sigma_{\\hat{x}}^2 +\n",
    "\\left(-\\frac{\\hat{x}}{\\hat{y}^2}\\right)^2\\sigma_{\\hat{y}}^2 +\n",
    "2\\left(\\frac{1}{\\hat{y}}\\right)\\left(-\\frac{\\hat{x}}{\\hat{y}^2}\\right)\\mathbb{C}\\mathrm{ov}(x,y)\n",
    "$\n",
    "\n",
    "$\\displaystyle \\left(\\frac{\\sigma_{\\widehat{x/y}}}{\\widehat{x/y}}\\right)^2 = \n",
    "\\left(\\frac{\\sigma_{\\hat{x}}}{\\hat{x}}\\right)^2 +\n",
    "\\left(\\frac{\\sigma_{\\hat{y}}}{\\hat{y}}\\right)^2\n",
    "-2\\frac{\\mathbb{C}\\mathrm{ov}(x,y)}{\\hat{x}\\hat{y}}\n",
    "$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
